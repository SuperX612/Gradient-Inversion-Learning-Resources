# Gradient Inversion Learning Resources

This GitHub repository summarizes existing gradient leakage attacks and defenses in federated learning. For more details, please refer to our comprehensive survey.

We commit to diligently maintaining and updating this repository monthly to ensure it remains a valuable and up-to-date resource.

**What are Gradient Leakage Attacks?**

Gradient Leakage Attack is a privacy attack in federated learning systems where the attacker reconstructs the client's private data from shared gradient.

**Why Gradient Leakage Attacks?**

Gradient leakage attacks pose a significant threat to data privacy in federated learning. Investigating and defending against these potential gradient leakage attacks in federated learning is crucial for implementing secure distributed machine learning.

Note: Gradient leakage attacks are also commonly referred to as "Gradient Reconstruction Attacks" or "Gradient Inversion Attacks."

## News

- 2024/04/18: I create this GitHub repository.

## Table of Contents

[Survey](#survey)

[Gradient Leakage Attacks](#gradient-leakage-attacks)

[Defenses for Gradient Leakage Attacks](#defenses-for-gradient-leakage-attacks)

## Survey



## Gradient Leakage Attacks



## Defenses for Gradient Leakage Attacks

